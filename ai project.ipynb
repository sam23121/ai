{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading https://files.pythonhosted.org/packages/99/c9/35d94c73e26b194c07a3d3adb82c06c38f76bebd3e1ba1e7195fb6f5a7cc/spacy-3.0.6-cp37-cp37m-win_amd64.whl (11.7MB)\n",
      "Collecting catalogue<2.1.0,>=2.0.3 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.4 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
      "Collecting pydantic<1.8.0,>=1.7.1 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/ab/48e9fba6288d5edc03d8d03834889df860eccda0d674c4b420e1599c8b36/pydantic-1.7.4-cp37-cp37m-win_amd64.whl (1.7MB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/1d/d281571b4c3b20fff183b485c6673c62878727119a849c7932651a8b5060/wasabi-0.8.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy) (1.19.5)\n",
      "Collecting thinc<8.1.0,>=8.0.3 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/fc/e44d8b7783f112545ef96b6988ec89eeb87dfd42b4a428c1189b7c5d5434/thinc-8.0.3-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting srsly<3.0.0,>=2.4.1 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f8/62520edb641dde8ba57f7ba9aa82f3c8e6567b8b8aacb690615c9800d156/srsly-2.4.1-cp37-cp37m-win_amd64.whl (450kB)\n",
      "Collecting blis<0.8.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/f3/2c18510d125d6af493120ca50fc8f2e3c21c9f58fb38d34c032f813dadcb/blis-0.7.4-cp37-cp37m-win_amd64.whl (6.5MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/04/19/f9b58e2e1ed1e4f6cb883dc6e1eb0b27271aac93243db57ecc81b00d9a23/preshed-3.0.5-cp37-cp37m-win_amd64.whl (108kB)\n",
      "Collecting packaging>=20.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/89/7ea760b4daa42653ece2380531c90f64788d979110a2ab51049d92f408af/packaging-20.9-py2.py3-none-any.whl (40kB)\n",
      "Collecting pathy>=0.3.5 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/7f/e4b81e6355e87c08a039cbc64c3044046ba4665a74e9b62246c71976a849/cymem-2.0.5-cp37-cp37m-win_amd64.whl\n",
      "Collecting typer<0.4.0,>=0.3.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy) (3.7.4.3)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/c7/3a/dc5400c423a1b85d7d081326d1f391676c10bb690aeae0c211ae4843739c/murmurhash-1.0.5-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in c:\\users\\sam\\anaconda3\\lib\\site-packages (from catalogue<2.1.0,>=2.0.3->spacy) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.2)\n",
      "Collecting smart-open<4.0.0,>=2.2.0 (from pathy>=0.3.5->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
      "Collecting click<7.2.0,>=7.1.1 (from typer<0.4.0,>=0.3.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in c:\\users\\sam\\anaconda3\\lib\\site-packages (from zipp>=0.5; python_version < \"3.8\"->catalogue<2.1.0,>=2.0.3->spacy) (7.2.0)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=8ae76f11ef6384678c5f175c76f1388c3edeefa597f871be68a46f2939a2fd2d\n",
      "  Stored in directory: C:\\Users\\sam\\AppData\\Local\\pip\\Cache\\wheels\\18\\88\\7c\\f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
      "Successfully built smart-open\n",
      "Installing collected packages: catalogue, spacy-legacy, pydantic, wasabi, srsly, blis, cymem, murmurhash, preshed, thinc, packaging, smart-open, click, typer, pathy, tqdm, spacy\n",
      "  Found existing installation: packaging 19.2\n",
      "    Uninstalling packaging-19.2:\n",
      "      Successfully uninstalled packaging-19.2\n",
      "  Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "  Found existing installation: tqdm 4.36.1\n",
      "    Uninstalling tqdm-4.36.1:\n",
      "      Successfully uninstalled tqdm-4.36.1\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.4 click-7.1.2 cymem-2.0.5 murmurhash-1.0.5 packaging-20.9 pathy-0.5.2 preshed-3.0.5 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 tqdm-4.60.0 typer-0.3.2 wasabi-0.8.2\n",
      "Collecting en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.22.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.60.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (41.4.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2019.9.11)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in c:\\users\\sam\\anaconda3\\lib\\site-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\sam\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\sam\\anaconda3\\lib\\site-packages (from zipp>=0.5; python_version < \"3.8\"->catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.2.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.0.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-20 12:26:32.374926: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-05-20 12:26:32.375530: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
      "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your text length is 1868\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "fname = r'C:\\Users\\sam\\Desktop\\stuff\\anacodaprojects\\summarization.txt'\n",
    "#if fname[-4:] == '.txt':\n",
    "f = open(fname)\n",
    "text = f.read()\n",
    "\n",
    "print('your text length is' , len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['because', 'up', 'off', 'together', 'very', \"'ve\", 'another', '‘ll', 'anywhere', 'sixty', 'forty', 'enough', 'before', 'thereby', 'hence', '’s', 'nowhere', 'make', 'while', \"'ll\", 'after', 'had', 'nor', 'empty', 'wherever', 'be', 'would', 'please', 'it', 'thru', 'name', 'whereby', 'whom', 'which', 'call', 'nine', 'my', 'keep', 'moreover', 'beyond', 'namely', 'not', 'over', 'somewhere', 'behind', 'any', 'into', 'your', 'therein', 'afterwards', 'anyone', 'serious', 'eleven', 'are', 'beside', 'sometime', 'throughout', 'me', 'thence', 'between', 'yourselves', 'and', 'themselves', 'several', 'ours', 'itself', 'more', 'five', 'mostly', 'top', 'whither', 'every', 'one', 'have', 'everyone', 'above', 'third', 'against', 'hers', 'but', 'all', 'many', 'mine', 'made', 're', 'becomes', 'everything', 'ourselves', \"'s\", 'some', 'although', 'alone', 'bottom', 'nevertheless', 'get', 'then', 'perhaps', 'somehow', 'former', 'few', 'since', 'as', 'among', 'him', 'if', 'only', 'becoming', 'herein', 'just', '‘re', 'in', 'its', 'fifty', 'part', 'see', 'anyway', 'from', 'whatever', 'well', 'they', 'hereafter', 'am', 'whence', 'you', 'neither', 'should', 'side', 'fifteen', 'nobody', 'really', 'us', 'own', 'always', 'towards', 'say', 'seems', 'though', 'where', \"n't\", 'eight', 'beforehand', 'that', 'whose', 'her', 'ten', 'does', 'these', 'even', 'hundred', 'else', 'upon', 'might', 'anyhow', 'using', 'than', 'we', 'could', 'further', 'toward', 'most', 'seemed', 'per', 'n’t', 'both', '‘ve', 'too', 'along', '‘d', '’m', 'seem', 'less', 'will', 'thereupon', 'those', 'yours', 'none', 'with', 'each', 'already', 'of', 'whereupon', 'been', 'sometimes', 'indeed', 'seeming', 'often', 'six', 'must', 'first', 'or', 'n‘t', 'again', \"'re\", 'twenty', 'least', 'yet', 'amongst', 'has', 'used', 'here', '‘m', 'take', 'myself', 'by', 'this', 'being', 'on', 'until', 'under', '’ve', 'other', 'for', 'the', 'last', 'once', '’ll', 'cannot', 'various', 'doing', 'during', 'move', 'however', 'regarding', 'show', 'no', 'almost', 'around', 'i', 'whoever', 'whole', 'across', 'everywhere', 'others', 'onto', 'rather', 'whereafter', 'latter', \"'d\", 'either', 'our', 'became', 'hereby', 'three', 'were', 'still', 'except', 'what', 'much', 'whereas', 'back', 'meanwhile', 'four', 'how', 'two', 'latterly', 'noone', 'through', 'do', 'so', 'due', 'about', 'next', 'done', 'something', 'yourself', 'when', 'such', 'also', 'become', 'thus', 'down', 'whether', 'someone', 'thereafter', 'may', 'ever', 'put', 'front', 'wherein', 'did', '’d', 'hereupon', 'is', 'below', 'therefore', 'formerly', 'unless', 'same', 'twelve', 'at', 'otherwise', 'was', 'an', 'anything', 'without', 'besides', 'out', 'herself', 'his', 'never', '‘s', 'quite', 'them', 'nothing', 'ca', 'via', 'within', 'she', 'a', '’re', 'why', 'whenever', 'now', 'himself', 'their', 'elsewhere', 'he', \"'m\", 'give', 'to', 'can', 'full', 'go', 'amount', 'who', 'there']\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
      "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'An', 'agent', '’s', 'behavior', 'can', 'be', 'based', 'on', 'both', 'its', 'own', 'experience', 'and', 'the', 'built', '-', 'in', 'knowledge', '\\n', 'used', 'in', 'constructing', 'the', 'agent', 'for', 'the', 'particular', 'environment', 'in', 'which', 'it', 'operates', '.', 'A', 'system', 'is', '\\n', 'autonomous4', 'to', 'the', 'extent', 'that', 'its', 'behavior', 'is', 'determined', 'by', 'its', 'own', 'experience', '.', 'It', 'would', 'be', '\\n', 'too', 'stringent', ',', 'though', ',', 'to', 'require', 'complete', 'autonomy', 'from', 'the', 'word', 'go', ':', 'when', 'the', 'agent', 'has', 'had', '\\n', 'little', 'or', 'no', 'experience', ',', 'it', 'would', 'have', 'to', 'act', 'randomly', 'unless', 'the', 'designer', 'gave', 'some', 'assistance', '.', '\\n', 'So', ',', 'just', 'as', 'evolution', 'provides', 'animals', 'with', 'enough', 'built', '-', 'in', 'reflexes', 'so', 'that', 'they', 'can', 'survive', 'long', '\\n', 'enough', 'to', 'learn', 'for', 'themselves', ',', 'it', 'would', 'be', 'reasonable', 'to', 'provide', 'an', 'artificial', 'intelligent', 'agent', '\\n', 'with', 'some', 'initial', 'knowledge', 'as', 'well', 'as', 'an', 'ability', 'to', 'learn', '.', '\\n', 'Autonomy', 'not', 'only', 'fits', 'in', 'with', 'our', 'intuition', ',', 'but', 'it', 'is', 'an', 'example', 'of', 'sound', 'engineering', '\\n', 'practices', '.', 'An', 'agent', 'that', 'operates', 'on', 'the', 'basis', 'of', 'built', '-', 'in', 'assumptions', 'will', 'only', 'operate', 'successfully', 'when', 'those', 'assumptions', 'hold', ',', 'and', 'thus', 'lacks', 'flexibility', '.', 'Consider', ',', 'for', 'example', ',', 'the', 'lowly', '\\n', 'dung', 'beetle', '.', 'After', 'digging', 'its', 'nest', 'and', 'laying', 'its', 'eggs', ',', 'it', 'fetches', 'a', 'ball', 'ofdung', 'from', 'a', 'nearby', 'heap', '\\n', 'to', 'plug', 'the', 'entrance', ';', 'if', 'the', 'ball', 'of', 'dung', 'is', 'removed', 'from', 'its', 'grasp', 'en', 'route', ',', 'the', 'beetle', 'continues', '\\n', 'on', 'and', 'pantomimes', 'plugging', 'the', 'nest', 'with', 'the', 'nonexistent', 'dung', 'ball', ',', 'never', 'noticing', 'that', 'it', 'is', '\\n', 'missing', '.', 'Evolution', 'has', 'built', 'an', 'assumption', 'into', 'the', 'beetle', '’s', 'behavior', ',', 'and', 'when', 'it', 'is', 'violated', ',', '\\n', 'unsuccessful', 'behavior', 'results', '.', 'A', 'truly', 'autonomous', 'intelligent', 'agent', 'should', 'be', 'able', 'to', 'operate', '\\n', 'successfully', 'in', 'a', 'wide', 'variety', 'of', 'environments', ',', 'given', 'sufficient', 'time', 'to', 'adapt', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = punctuation + '\\n'\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': 6, 'behavior': 4, 'based': 1, 'experience': 3, 'built': 4, 'knowledge': 2, 'constructing': 1, 'particular': 1, 'environment': 1, 'operates': 2, 'system': 1, 'autonomous4': 1, 'extent': 1, 'determined': 1, 'stringent': 1, 'require': 1, 'complete': 1, 'autonomy': 1, 'word': 1, 'little': 1, 'act': 1, 'randomly': 1, 'designer': 1, 'gave': 1, 'assistance': 1, 'evolution': 1, 'provides': 1, 'animals': 1, 'reflexes': 1, 'survive': 1, 'long': 1, 'learn': 2, 'reasonable': 1, 'provide': 1, 'artificial': 1, 'intelligent': 2, 'initial': 1, 'ability': 1, 'Autonomy': 1, 'fits': 1, 'intuition': 1, 'example': 2, 'sound': 1, 'engineering': 1, 'practices': 1, 'basis': 1, 'assumptions': 2, 'operate': 2, 'successfully': 2, 'hold': 1, 'lacks': 1, 'flexibility': 1, 'Consider': 1, 'lowly': 1, 'dung': 3, 'beetle': 3, 'digging': 1, 'nest': 2, 'laying': 1, 'eggs': 1, 'fetches': 1, 'ball': 3, 'ofdung': 1, 'nearby': 1, 'heap': 1, 'plug': 1, 'entrance': 1, 'removed': 1, 'grasp': 1, 'en': 1, 'route': 1, 'continues': 1, 'pantomimes': 1, 'plugging': 1, 'nonexistent': 1, 'noticing': 1, 'missing': 1, 'Evolution': 1, 'assumption': 1, 'violated': 1, 'unsuccessful': 1, 'results': 1, 'truly': 1, 'autonomous': 1, 'able': 1, 'wide': 1, 'variety': 1, 'environments': 1, 'given': 1, 'sufficient': 1, 'time': 1, 'adapt': 1}\n"
     ]
    }
   ],
   "source": [
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1\n",
    "#print(word_frequencies.keys())\n",
    "#print(word_frequencies.values())\n",
    "print(word_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': 1.0, 'behavior': 0.6666666666666666, 'based': 0.16666666666666666, 'experience': 0.5, 'built': 0.6666666666666666, 'knowledge': 0.3333333333333333, 'constructing': 0.16666666666666666, 'particular': 0.16666666666666666, 'environment': 0.16666666666666666, 'operates': 0.3333333333333333, 'system': 0.16666666666666666, 'autonomous4': 0.16666666666666666, 'extent': 0.16666666666666666, 'determined': 0.16666666666666666, 'stringent': 0.16666666666666666, 'require': 0.16666666666666666, 'complete': 0.16666666666666666, 'autonomy': 0.16666666666666666, 'word': 0.16666666666666666, 'little': 0.16666666666666666, 'act': 0.16666666666666666, 'randomly': 0.16666666666666666, 'designer': 0.16666666666666666, 'gave': 0.16666666666666666, 'assistance': 0.16666666666666666, 'evolution': 0.16666666666666666, 'provides': 0.16666666666666666, 'animals': 0.16666666666666666, 'reflexes': 0.16666666666666666, 'survive': 0.16666666666666666, 'long': 0.16666666666666666, 'learn': 0.3333333333333333, 'reasonable': 0.16666666666666666, 'provide': 0.16666666666666666, 'artificial': 0.16666666666666666, 'intelligent': 0.3333333333333333, 'initial': 0.16666666666666666, 'ability': 0.16666666666666666, 'Autonomy': 0.16666666666666666, 'fits': 0.16666666666666666, 'intuition': 0.16666666666666666, 'example': 0.3333333333333333, 'sound': 0.16666666666666666, 'engineering': 0.16666666666666666, 'practices': 0.16666666666666666, 'basis': 0.16666666666666666, 'assumptions': 0.3333333333333333, 'operate': 0.3333333333333333, 'successfully': 0.3333333333333333, 'hold': 0.16666666666666666, 'lacks': 0.16666666666666666, 'flexibility': 0.16666666666666666, 'Consider': 0.16666666666666666, 'lowly': 0.16666666666666666, 'dung': 0.5, 'beetle': 0.5, 'digging': 0.16666666666666666, 'nest': 0.3333333333333333, 'laying': 0.16666666666666666, 'eggs': 0.16666666666666666, 'fetches': 0.16666666666666666, 'ball': 0.5, 'ofdung': 0.16666666666666666, 'nearby': 0.16666666666666666, 'heap': 0.16666666666666666, 'plug': 0.16666666666666666, 'entrance': 0.16666666666666666, 'removed': 0.16666666666666666, 'grasp': 0.16666666666666666, 'en': 0.16666666666666666, 'route': 0.16666666666666666, 'continues': 0.16666666666666666, 'pantomimes': 0.16666666666666666, 'plugging': 0.16666666666666666, 'nonexistent': 0.16666666666666666, 'noticing': 0.16666666666666666, 'missing': 0.16666666666666666, 'Evolution': 0.16666666666666666, 'assumption': 0.16666666666666666, 'violated': 0.16666666666666666, 'unsuccessful': 0.16666666666666666, 'results': 0.16666666666666666, 'truly': 0.16666666666666666, 'autonomous': 0.16666666666666666, 'able': 0.16666666666666666, 'wide': 0.16666666666666666, 'variety': 0.16666666666666666, 'environments': 0.16666666666666666, 'given': 0.16666666666666666, 'sufficient': 0.16666666666666666, 'time': 0.16666666666666666, 'adapt': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency\n",
    "\n",
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", An agent’s behavior can be based on both its own experience and the built-in knowledge\n",
      "used in constructing the agent for the particular environment in which it operates., A system is\n",
      "autonomous4 to the extent that its behavior is determined by its own experience., It would be\n",
      "too stringent, though, to require complete autonomy from the word go: when the agent has had\n",
      "little or no experience, it would have to act randomly unless the designer gave some assistance.\n",
      ", So, just as evolution provides animals with enough built-in reflexes so that they can survive long\n",
      "enough to learn for themselves, it would be reasonable to provide an artificial intelligent agent\n",
      "with some initial knowledge as well as an ability to learn., \n",
      ", Autonomy not only fits in with our intuition, but it is an example of sound engineering\n",
      "practices., An agent that operates on the basis of built-in assumptions will only operate successfully when those assumptions hold, and thus lacks flexibility., Consider, for example, the lowly\n",
      "dung beetle., After digging its nest and laying its eggs, it fetches a ball ofdung from a nearby heap\n",
      "to plug the entrance; if the ball of dung is removed from its grasp en route, the beetle continues\n",
      "on and pantomimes plugging the nest with the nonexistent dung ball, never noticing that it is\n",
      "missing., Evolution has built an assumption into the beetle’s behavior, and when it is violated,\n",
      "unsuccessful behavior results., A truly autonomous intelligent agent should be able to operate\n",
      "successfully in a wide variety of environments, given sufficient time to adapt.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{An agent’s behavior can be based on both its own experience and the built-in knowledge\n",
       " used in constructing the agent for the particular environment in which it operates.: 5.166666666666667,\n",
       " A system is\n",
       " autonomous4 to the extent that its behavior is determined by its own experience.: 1.8333333333333333,\n",
       " It would be\n",
       " too stringent, though, to require complete autonomy from the word go: when the agent has had\n",
       " little or no experience, it would have to act randomly unless the designer gave some assistance.: 3.3333333333333326,\n",
       " So, just as evolution provides animals with enough built-in reflexes so that they can survive long\n",
       " enough to learn for themselves, it would be reasonable to provide an artificial intelligent agent\n",
       " with some initial knowledge as well as an ability to learn.: 4.833333333333333,\n",
       " Autonomy not only fits in with our intuition, but it is an example of sound engineering\n",
       " practices.: 1.3333333333333333,\n",
       " An agent that operates on the basis of built-in assumptions will only operate successfully when those assumptions hold, and thus lacks flexibility.: 4.0,\n",
       " Consider, for example, the lowly\n",
       " dung beetle.: 1.5,\n",
       " After digging its nest and laying its eggs, it fetches a ball ofdung from a nearby heap\n",
       " to plug the entrance; if the ball of dung is removed from its grasp en route, the beetle continues\n",
       " on and pantomimes plugging the nest with the nonexistent dung ball, never noticing that it is\n",
       " missing.: 6.833333333333334,\n",
       " Evolution has built an assumption into the beetle’s behavior, and when it is violated,\n",
       " unsuccessful behavior results.: 3.3333333333333326,\n",
       " A truly autonomous intelligent agent should be able to operate\n",
       " successfully in a wide variety of environments, given sufficient time to adapt.: 3.6666666666666656}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "                \n",
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*0.1)\n",
    "print(len(sentence_tokens))\n",
    "#print(select_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[After digging its nest and laying its eggs, it fetches a ball ofdung from a nearby heap\n",
       " to plug the entrance; if the ball of dung is removed from its grasp en route, the beetle continues\n",
       " on and pantomimes plugging the nest with the nonexistent dung ball, never noticing that it is\n",
       " missing.]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = [word.text for word in summary]\n",
    "summary = ' '.join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
      "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1869"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
